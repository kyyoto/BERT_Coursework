{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZDB9SRi4yIAJCRH5uyoPUjTraO6PT_KQ","authorship_tag":"ABX9TyNdZJuVRt3v+FPXOE8/q22y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99CPmkhxKyJ4","executionInfo":{"status":"ok","timestamp":1682425353396,"user_tz":-180,"elapsed":15751,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"75627eb9-8625-4b8e-e144-f2e589233d93"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.0 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","execution_count":38,"metadata":{"id":"_bArpP1aHHoF","executionInfo":{"status":"ok","timestamp":1682438379269,"user_tz":-180,"elapsed":304,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"outputs":[],"source":["import glob\n","import json\n","\n","files = glob.glob(r\"/content/drive/MyDrive/Coursework/Q_A/*.json\")"]},{"cell_type":"code","source":["texts = []\n","labels = []\n","\n","def concat_data(path):\n","    with open(path, 'r', encoding='utf-8') as file:\n","        data = json.load(file)\n","    for question, anss in data.items():\n","        for i in range(len(anss)):\n","            texts.append(question + '||||' + anss[i])\n","            labels.append(i)\n","            \n","for file in files:\n","    concat_data(file)"],"metadata":{"id":"M6OppWC6JcaI","executionInfo":{"status":"ok","timestamp":1682438400737,"user_tz":-180,"elapsed":20263,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizerFast, BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","\n","class TextLabelDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer):\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.encodings = tokenizer(texts, max_length=64, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return item\n","\n","\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"cointegrated/rubert-tiny\")\n","\n","train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.25, random_state=42)\n","\n","train_dataset = TextLabelDataset(train_texts, train_labels, tokenizer)\n","val_dataset = TextLabelDataset(val_texts, val_labels, tokenizer)\n","test_dataset = TextLabelDataset(test_texts, test_labels, tokenizer)"],"metadata":{"id":"HH420A8LJwVK","executionInfo":{"status":"ok","timestamp":1682438403376,"user_tz":-180,"elapsed":2643,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["num_labels = len(set(labels))\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","\n","# Set up training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n",")\n","\n","# Set up the trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n","# Train the model\n","trainer.train()"],"metadata":{"id":"kQCn-mDvK_sU","executionInfo":{"status":"ok","timestamp":1682441428339,"user_tz":-180,"elapsed":3024965,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"colab":{"base_uri":"https://localhost:8080/","height":353},"outputId":"5e6e37e9-93ce-4441-e2f2-dd1680aebf05"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='666' max='666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [666/666 50:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.491300</td>\n","      <td>1.544783</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.449800</td>\n","      <td>1.511690</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.450700</td>\n","      <td>1.486895</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=666, training_loss=1.467863390753577, metrics={'train_runtime': 3021.3135, 'train_samples_per_second': 1.762, 'train_steps_per_second': 0.22, 'total_flos': 175153738089600.0, 'train_loss': 1.467863390753577, 'epoch': 3.0})"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["y_true = []\n","for i in test_dataset:\n","  y_true.append(i['labels'].detach().cpu().numpy())"],"metadata":{"id":"i0aV73HVm-13","executionInfo":{"status":"ok","timestamp":1682441428340,"user_tz":-180,"elapsed":25,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["import numpy\n","result = numpy.argmax(trainer.predict(test_dataset).predictions, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"gcjsAg6ChYfh","executionInfo":{"status":"ok","timestamp":1682441514819,"user_tz":-180,"elapsed":86484,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"f8202aaa-552f-4acf-fc5a-06f90e6aa600"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score, recall_score\n","\n","# Расчет метрик F1, accuracy и NDCG\n","f1 = f1_score(y_true, result, average='weighted')\n","accuracy = accuracy_score(y_true, result)\n","recall = recall_score(y_true, result, average='weighted')\n","\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","from transformers import BertTokenizerFast"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R91_wqgjLAd_","executionInfo":{"status":"ok","timestamp":1682446843625,"user_tz":-180,"elapsed":470,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"6bd99f5b-f1b6-40f4-8350-d50ba53d8fe5"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 0.3184\n","Accuracy: 0.4865\n","Recall: 0.4865\n"]}]},{"cell_type":"code","source":["from transformers import BertConfig\n","\n","config = BertConfig.from_json_file(\"/content/drive/MyDrive/Coursework/config.json\")\n","own_model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Coursework/pytorch_model.bin\", config=config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iDtYyhyvWkx","executionInfo":{"status":"ok","timestamp":1682441519284,"user_tz":-180,"elapsed":4507,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"11f70aa5-5967-4251-8929-621f0845b23f"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Coursework/pytorch_model.bin were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Coursework/pytorch_model.bin and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["own_model.num_labels = num_labels\n","own_model.classifier = torch.nn.Linear(in_features=768, out_features=num_labels)"],"metadata":{"id":"1K-UC-JIz_JD","executionInfo":{"status":"ok","timestamp":1682441519285,"user_tz":-180,"elapsed":12,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","own_model.to(device)\n","\n","# Set up the optimizer and scheduler\n","optimizer = AdamW(own_model.parameters(), lr=5e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=len(train_loader) * 3)\n","\n","# Training loop\n","num_epochs = 3\n","\n","for epoch in range(num_epochs):\n","    own_model.train()\n","    for batch in train_loader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = own_model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","\n","    # Validation loop\n","    own_model.eval()\n","    total_val_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = own_model(**batch)\n","            val_loss = outputs.loss\n","            total_val_loss += val_loss.item()\n","\n","    avg_val_loss = total_val_loss / len(val_loader)\n","    print(f\"Epoch: {epoch + 1}, Validation Loss: {avg_val_loss}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHCSo8jsvmeT","executionInfo":{"status":"ok","timestamp":1682444777868,"user_tz":-180,"elapsed":3258594,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"ef6bb2c1-876e-474a-f7a6-13c1240f4e04"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Validation Loss: 1.5639895675955593\n","Epoch: 2, Validation Loss: 1.524721257992693\n","Epoch: 3, Validation Loss: 1.4877780204689182\n"]}]},{"cell_type":"code","source":["own_model.eval()\n","preds = []\n","with torch.no_grad():\n","  for batch in val_loader:\n","      batch = {k: v.to(device) for k, v in batch.items()}\n","      outputs = own_model(**batch)\n","      preds.append(torch.argmax(outputs.logits, dim=1).detach().cpu().numpy())"],"metadata":{"id":"i_JrKR9J5Btt","executionInfo":{"status":"ok","timestamp":1682444870550,"user_tz":-180,"elapsed":92709,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","for pred in preds:\n","  for pr in pred:\n","    y_pred.append(pr)"],"metadata":{"id":"paujjruBF1zO","executionInfo":{"status":"ok","timestamp":1682444870551,"user_tz":-180,"elapsed":28,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score, recall_score\n","\n","# Расчет метрик F1, accuracy и recall\n","f1 = f1_score(y_true, y_pred, average='weighted')\n","accuracy = accuracy_score(y_true, y_pred)\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"recall: {recall:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mm4q3k8BHV9a","executionInfo":{"status":"ok","timestamp":1682444870551,"user_tz":-180,"elapsed":27,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}},"outputId":"b54225c6-eedb-440e-86a5-2da4e54ec2f4"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 0.3184\n","Accuracy: 0.4865\n","recall: 0.4865\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cfhR2zTyHu66","executionInfo":{"status":"ok","timestamp":1682444870552,"user_tz":-180,"elapsed":27,"user":{"displayName":"Антон Орлов","userId":"12650910137909203574"}}},"execution_count":50,"outputs":[]}]}